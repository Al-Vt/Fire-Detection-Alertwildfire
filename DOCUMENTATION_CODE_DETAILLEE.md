# Documentation Code D√©taill√©e - Fire Detection System

**Projet :** Syst√®me de D√©tection d'Incendies Automatis√©
**Auteur :** Axel Vilamot
**Date :** 2026-01-09
**Technologies :** Python, YOLOv8, Airflow, MLflow, PostgreSQL, AWS S3

---

# Table des Mati√®res

1. [Architecture Globale](#architecture-globale)
2. [Scraping (scraper/)](#scraping)
3. [D√©tection IA (model/)](#detection-ia)
4. [Monitoring (monitoring/)](#monitoring)
5. [R√©entra√Ænement (retraining/)](#reentrainement)
6. [Orchestration Airflow (dags/)](#orchestration-airflow)
7. [Scripts Utilitaires](#scripts-utilitaires)
8. [Configuration](#configuration)

---

# Architecture Globale

## Vue d'ensemble du syst√®me

Le syst√®me Fire Detection est compos√© de 6 modules principaux :

1. **Scraping** : Capture d'images depuis 165 cam√©ras
2. **Stockage** : S3 (images) + PostgreSQL (m√©tadonn√©es)
3. **D√©tection** : YOLOv8 fine-tun√© pour d√©tecter le feu
4. **Monitoring** : Suivi des performances du mod√®le
5. **R√©entra√Ænement** : Am√©lioration automatique du mod√®le
6. **Orchestration** : Airflow pour automatiser tout le pipeline

## Flux de donn√©es

```
Cam√©ras ‚Üí Scraper ‚Üí S3 + PostgreSQL ‚Üí YOLOv8 ‚Üí D√©tection
                                                     ‚Üì
                                        Email Alerte + Monitoring
                                                     ‚Üì
                                        M√©triques Quotidiennes
                                                     ‚Üì
                            Si d√©gradation ‚Üí R√©entra√Ænement Automatique
```

---

# Scraping

## scraper/scraper.py

**Objectif :** Capturer des screenshots des cam√©ras de surveillance foresti√®re et les stocker dans S3.

### Imports et Configuration

```python
import os
import time
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import boto3
from database import DatabaseManager
```

**Explication :**
- `selenium` : Pilotage automatique du navigateur Chrome
- `boto3` : Client AWS pour upload S3
- `database` : Gestion PostgreSQL (Neon)

### Classe AlertWildfireScraper

```python
class AlertWildfireScraper:
    def __init__(self):
        self.db = DatabaseManager()
        self.s3_client = boto3.client('s3')
        self.bucket_name = os.getenv('S3_BUCKET_NAME')
        self.driver = None
        self.batch_id = None
```

**Explication :**
- Initialise la connexion √† la base de donn√©es
- Configure le client S3 avec les credentials du .env
- Pr√©pare le driver Selenium (sera cr√©√© dans start())

### M√©thode start()

```python
def start(self):
    """D√©marre le navigateur Chrome en mode headless"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')  # Pas d'interface graphique
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--window-size=1920,1080')

    self.driver = webdriver.Chrome(options=chrome_options)
    self.batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
```

**Explication :**
- `--headless` : Ex√©cution sans fen√™tre (serveur)
- `--no-sandbox` : N√©cessaire pour Docker
- `--window-size` : Taille du screenshot (HD)
- `batch_id` : Identifiant unique pour ce cycle de scraping

### M√©thode scrape_camera()

```python
def scrape_camera(self, url, camera_name):
    """
    Scrape une cam√©ra individuelle

    Args:
        url: URL de la cam√©ra
        camera_name: Nom extrait de l'URL

    Returns:
        bool: True si succ√®s, False sinon
    """
    try:
        # 1. Naviguer vers l'URL
        self.driver.get(url)

        # 2. Attendre que l'image soit charg√©e (max 10s)
        WebDriverWait(self.driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, 'img'))
        )

        time.sleep(2)  # Attendre stabilisation compl√®te

        # 3. Prendre le screenshot
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"fire_detection/{self.batch_id}/{camera_name}_{timestamp}.png"

        screenshot = self.driver.get_screenshot_as_png()

        # 4. Upload vers S3
        self.s3_client.put_object(
            Bucket=self.bucket_name,
            Key=filename,
            Body=screenshot,
            ContentType='image/png'
        )

        # 5. Enregistrer dans PostgreSQL
        self.db.insert_image(
            batch_id=self.batch_id,
            camera_name=camera_name,
            s3_path=filename,
            status='NEW'
        )

        return True

    except Exception as e:
        print(f"Erreur scraping {camera_name}: {e}")
        return False
```

**Explication d√©taill√©e :**

1. **Navigation** : Selenium ouvre l'URL de la cam√©ra
2. **Attente intelligente** : WebDriverWait attend que les images soient charg√©es (√©vite screenshots vides)
3. **Screenshot** : Capture l'√©cran entier en PNG
4. **Upload S3** : Stocke l'image dans le bucket avec un chemin structur√©
5. **Base de donn√©es** : Enregistre les m√©tadonn√©es (path S3, camera, batch)

**Gestion d'erreurs :**
- Timeout si cam√©ra offline (normal, ~40% des cam√©ras)
- Exception captur√©e pour ne pas bloquer le cycle complet

### M√©thode scrape_all()

```python
def scrape_all(self, max_cameras=None):
    """
    Scrape toutes les cam√©ras (ou un nombre limit√©)

    Args:
        max_cameras: Nombre max de cam√©ras (None = toutes)

    Returns:
        str: batch_id du cycle
    """
    success_count = 0
    fail_count = 0

    cameras_to_scrape = self.CAMERA_URLS[:max_cameras] if max_cameras else self.CAMERA_URLS

    for url in cameras_to_scrape:
        # Extraire le nom de la cam√©ra depuis l'URL
        camera_name = url.split('currentFirecam=')[1].split('&')[0]

        if self.scrape_camera(url, camera_name):
            success_count += 1
        else:
            fail_count += 1

        time.sleep(1)  # D√©lai entre chaque cam√©ra (politesse)

    print(f"Scraping termin√©: {success_count} succ√®s, {fail_count} √©checs")
    return self.batch_id
```

**Explication :**
- It√®re sur la liste des 165 URLs
- Extrait le nom de la cam√©ra depuis l'URL (ex: `ca-lassen-1`)
- Compte les succ√®s/√©checs
- D√©lai de 1s entre cam√©ras (√©viter surcharge serveur)

**Taux de succ√®s attendu :** 60% (normal, cam√©ras parfois offline)

---

## scraper/database.py

**Objectif :** G√©rer toutes les interactions avec PostgreSQL (Neon).

### Classe DatabaseManager

```python
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()

class DatabaseManager:
    def __init__(self):
        """Initialise la connexion √† Neon PostgreSQL"""
        self.conn = psycopg2.connect(os.getenv('DATABASE_URL'))
        self.cur = self.conn.cursor()
```

**Explication :**
- Charge `DATABASE_URL` depuis .env
- Cr√©e une connexion persistante
- Curseur pour ex√©cuter les requ√™tes SQL

### M√©thode insert_image()

```python
def insert_image(self, batch_id, camera_name, s3_path, status='NEW'):
    """
    Ins√®re une nouvelle image dans la base

    Args:
        batch_id: ID du cycle de scraping
        camera_name: Nom de la cam√©ra
        s3_path: Chemin dans S3
        status: Statut initial (NEW/ANALYZED)
    """
    self.cur.execute("""
        INSERT INTO images
        (batch_id, camera_name, s3_path, status, captured_at)
        VALUES (%s, %s, %s, %s, NOW())
        RETURNING id
    """, (batch_id, camera_name, s3_path, status))

    self.conn.commit()
    return self.cur.fetchone()[0]  # Retourne l'ID g√©n√©r√©
```

**Explication :**
- Requ√™te SQL INSERT avec param√®tres s√©curis√©s (√©vite SQL injection)
- `NOW()` : Timestamp automatique
- `RETURNING id` : R√©cup√®re l'ID auto-incr√©ment√©
- `commit()` : Valide la transaction

### M√©thode get_pending_images()

```python
def get_pending_images(self, limit=None):
    """
    R√©cup√®re les images en attente d'analyse

    Args:
        limit: Nombre max d'images (None = toutes)

    Returns:
        list: Liste de dictionnaires avec les infos images
    """
    query = """
        SELECT id, batch_id, camera_name, s3_path
        FROM images
        WHERE status = 'NEW'
        ORDER BY created_at ASC
    """

    if limit:
        query += f" LIMIT {limit}"

    self.cur.execute(query)

    images = []
    for row in self.cur.fetchall():
        images.append({
            'id': row[0],
            'batch_id': row[1],
            'camera_name': row[2],
            's3_path': row[3]
        })

    return images
```

**Explication :**
- Filtre sur `status = 'NEW'` (non analys√©es)
- Trie par date de cr√©ation (FIFO)
- Convertit les r√©sultats en dictionnaires (plus facile √† manipuler)

### M√©thode update_prediction()

```python
def update_prediction(self, image_id, fire_detected, confidence, bbox):
    """
    Met √† jour les r√©sultats de pr√©diction

    Args:
        image_id: ID de l'image
        fire_detected: True/False
        confidence: Confiance du mod√®le (0-1)
        bbox: Bounding box [x, y, w, h]
    """
    self.cur.execute("""
        UPDATE images
        SET
            fire_detected = %s,
            confidence = %s,
            bbox = %s,
            status = 'ANALYZED',
            updated_at = NOW()
        WHERE id = %s
    """, (fire_detected, confidence, psycopg2.extras.Json(bbox), image_id))

    self.conn.commit()
```

**Explication :**
- Met √† jour plusieurs colonnes en une requ√™te
- `psycopg2.extras.Json(bbox)` : Stocke le tableau comme JSONB
- Change le status √† 'ANALYZED' pour ne pas retraiter

---

# D√©tection IA

## model/inference.py

**Objectif :** Charger le mod√®le YOLOv8 et effectuer les pr√©dictions avec logging automatique.

### Imports et Configuration

```python
import os
import logging
import time
from ultralytics import YOLO
import psycopg2
from datetime import datetime
from dotenv import load_dotenv

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

load_dotenv()
DATABASE_URL = os.getenv('DATABASE_URL')
```

**Explication :**
- `ultralytics` : Biblioth√®que officielle YOLOv8
- Logging configur√© pour tracer toutes les op√©rations
- Connexion √† Neon pour le monitoring

### Classe FireDetector

```python
class FireDetector:
    def __init__(self, model_path='weights/best.pt'):
        """
        Initialise le d√©tecteur de feu

        Args:
            model_path: Chemin vers le mod√®le YOLOv8 fine-tun√©
        """
        self.model_path = model_path
        logging.info(f"Chargement du mod√®le depuis {self.model_path}...")

        try:
            self.model = YOLO(self.model_path)
            logging.info("Mod√®le charg√© avec succ√®s.")
        except Exception as e:
            logging.error(f"Erreur lors du chargement du mod√®le : {e}")
            raise e
```

**Explication :**
- Charge le mod√®le YOLOv8 personnalis√© (fine-tun√© sur Pyro-SDIS)
- Gestion d'erreur si le fichier .pt est manquant
- Log toutes les √©tapes pour d√©bogage

### M√©thode predict()

```python
def predict(self, image_path, conf_threshold=0.4, image_id=None,
            batch_id=None, camera_name=None, s3_path=None):
    """
    D√©tecte le feu dans une image

    Args:
        image_path: Chemin local de l'image
        conf_threshold: Seuil de confiance minimum (d√©faut 0.4)
        image_id, batch_id, camera_name, s3_path: M√©tadonn√©es pour monitoring

    Returns:
        list: Liste des d√©tections [{'class': 'fire', 'confidence': 0.85, 'bbox': [x,y,w,h]}]
    """
    logging.info(f"Analyse de l'image : {image_path}")

    # 1. MESURER LE TEMPS D'INF√âRENCE
    start_time = time.time()

    # 2. INF√âRENCE YOLO
    results = self.model.predict(
        source=image_path,
        conf=conf_threshold,  # Seuil de confiance
        imgsz=960,            # Taille image (m√™me que l'entra√Ænement)
        save=False            # Ne pas sauvegarder les r√©sultats
    )

    inference_time_ms = (time.time() - start_time) * 1000

    # 3. PARSER LES R√âSULTATS
    detections = []
    fire_detected = False
    max_confidence = 0.0
    best_bbox = None

    for result in results:
        for box in result.boxes:
            cls_id = int(box.cls[0])        # ID de la classe
            confidence = float(box.conf[0])  # Confiance
            coords = box.xywhn[0].tolist()  # Coordonn√©es normalis√©es

            # Classe 0 = fire (selon data.yaml)
            if cls_id == 0:
                fire_detected = True

                if confidence > max_confidence:
                    max_confidence = confidence
                    best_bbox = coords

                detections.append({
                    "class": "fire",
                    "confidence": confidence,
                    "bbox": coords  # [x_center, y_center, width, height]
                })

    # 4. LOGGER DANS NEON (MONITORING)
    self._log_prediction(
        image_id=image_id,
        batch_id=batch_id,
        camera_name=camera_name,
        s3_path=s3_path,
        fire_detected=fire_detected,
        confidence=max_confidence if fire_detected else None,
        bbox=best_bbox,
        inference_time_ms=inference_time_ms,
        image_size_bytes=os.path.getsize(image_path) if os.path.exists(image_path) else None
    )

    # 5. LOG R√âSULTAT
    if detections:
        logging.warning(f"FEU DETECTE ! ({len(detections)} foyers)")
    else:
        logging.info("Aucune anomalie detectee.")

    return detections
```

**Explication d√©taill√©e :**

**√âtape 1 : Mesure du temps**
- `start_time` : Timestamp avant inf√©rence
- Utilis√© pour d√©tecter si le mod√®le ralentit (monitoring)

**√âtape 2 : Inf√©rence YOLOv8**
- `conf=0.4` : Ne garde que les d√©tections avec confiance ‚â• 40%
- `imgsz=960` : M√™me taille que l'entra√Ænement (important!)
- `save=False` : Ne sauvegarde pas les images annot√©es (gain de performance)

**√âtape 3 : Parsing**
- `result.boxes` : Liste des bo√Ætes d√©tect√©es
- `box.cls[0]` : Classe (0 = fire, selon data.yaml)
- `box.conf[0]` : Confiance (0-1)
- `box.xywhn[0]` : Coordonn√©es normalis√©es (0-1)
  - x, y : Centre de la bo√Æte
  - w, h : Largeur, hauteur

**√âtape 4 : Logging monitoring**
- Sauvegarde CHAQUE pr√©diction dans `model_predictions`
- Permet de calculer les m√©triques quotidiennes
- D√©tecte les d√©gradations du mod√®le

**√âtape 5 : Log console**
- WARNING si feu (facile √† rep√©rer dans les logs)
- INFO si rien (pas d'alerte)

### M√©thode _log_prediction()

```python
def _log_prediction(self, image_id, batch_id, camera_name, s3_path,
                    fire_detected, confidence, bbox, inference_time_ms, image_size_bytes):
    """
    Log la pr√©diction dans Neon PostgreSQL pour monitoring

    Cette fonction est CRITIQUE pour le syst√®me de monitoring.
    Elle enregistre chaque pr√©diction pour calculer les m√©triques quotidiennes.
    """
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()

        cur.execute("""
            INSERT INTO model_predictions
            (image_id, batch_id, camera_name, fire_detected, confidence, bbox,
             inference_time_ms, image_size_bytes, s3_path, prediction_timestamp)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            image_id,
            batch_id,
            camera_name,
            fire_detected,
            confidence,
            None if bbox is None else psycopg2.extras.Json(bbox),
            inference_time_ms,
            image_size_bytes,
            s3_path,
            datetime.now()
        ))

        conn.commit()
        cur.close()
        conn.close()

        logging.info(f"Prediction loggee dans Neon (fire_detected={fire_detected}, confidence={confidence})")

    except Exception as e:
        logging.error(f"Erreur lors du logging de la prediction: {e}")
        # Ne pas lever d'exception pour ne pas bloquer le pipeline
```

**Explication :**
- Connexion s√©par√©e (robustesse si probl√®me r√©seau)
- Sauvegarde TOUTES les infos de pr√©diction
- JSONB pour la bbox (flexible, requ√™table)
- Exception captur√©e : le logging ne doit pas bloquer le pipeline principal

**Donn√©es stock√©es :**
- `image_id` : Lien avec la table images
- `fire_detected` : Boolean (feu oui/non)
- `confidence` : 0-1 (NULL si pas de feu)
- `bbox` : Coordonn√©es de la bo√Æte
- `inference_time_ms` : Performance du mod√®le
- `image_size_bytes` : Taille de l'image (d√©tecte images corrompues)

---

# Monitoring

## monitoring/metrics.py

**Objectif :** Calculer les m√©triques quotidiennes et d√©tecter les d√©gradations du mod√®le.

### Configuration des Seuils

```python
# Seuils d'alerte pour d√©tecter les d√©gradations
THRESHOLDS = {
    'min_avg_confidence': 0.60,      # Confiance moyenne minimum acceptable
    'max_avg_confidence': 0.95,      # Confiance moyenne maximum (possible overfitting)
    'min_daily_predictions': 50,     # Minimum de pr√©dictions attendues par jour
    'max_inference_time_ms': 5000,   # Temps maximum d'inf√©rence acceptable (5s)
}
```

**Explication :**
- `min_avg_confidence` : Si la confiance moyenne baisse < 60%, le mod√®le d√©grade
- `max_avg_confidence` : Si > 95%, possible overfitting (le mod√®le est trop s√ªr)
- `min_daily_predictions` : Si < 50, probl√®me de scraping
- `max_inference_time_ms` : Si > 5s, probl√®me de performance

### Classe ModelMonitor

```python
class ModelMonitor:
    def __init__(self):
        """Initialise le monitor du mod√®le"""
        self.conn = psycopg2.connect(DATABASE_URL)
        self.cur = self.conn.cursor()
        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
```

### M√©thode calculate_daily_metrics()

```python
def calculate_daily_metrics(self, target_date=None):
    """
    Calcule les m√©triques quotidiennes

    Args:
        target_date: Date cible (d√©faut: hier)

    Returns:
        dict: M√©triques agr√©g√©es
    """
    if target_date is None:
        target_date = (datetime.now() - timedelta(days=1)).date()

    logging.info(f"Calcul des metriques pour {target_date}")

    # REQU√äTE SQL AGR√âG√âE
    self.cur.execute("""
        SELECT
            COUNT(*) as total_predictions,
            SUM(CASE WHEN fire_detected = TRUE THEN 1 ELSE 0 END) as fire_detections,
            AVG(CASE WHEN fire_detected = TRUE THEN confidence ELSE NULL END) as avg_confidence,
            MIN(CASE WHEN fire_detected = TRUE THEN confidence ELSE NULL END) as min_confidence,
            MAX(CASE WHEN fire_detected = TRUE THEN confidence ELSE NULL END) as max_confidence,
            STDDEV(CASE WHEN fire_detected = TRUE THEN confidence ELSE NULL END) as std_confidence,
            AVG(inference_time_ms) as avg_inference_time_ms,
            COUNT(DISTINCT camera_name) as unique_cameras
        FROM model_predictions
        WHERE DATE(prediction_timestamp) = %s
    """, (target_date,))

    result = self.cur.fetchone()

    if result[0] == 0:
        logging.warning(f"Aucune prediction pour {target_date}")
        return None

    # FORMATER LES R√âSULTATS
    metrics = {
        'metric_date': target_date,
        'total_predictions': result[0],
        'fire_detections': result[1] or 0,
        'avg_confidence': float(result[2]) if result[2] else None,
        'min_confidence': float(result[3]) if result[3] else None,
        'max_confidence': float(result[4]) if result[4] else None,
        'std_confidence': float(result[5]) if result[5] else None,
        'avg_inference_time_ms': float(result[6]) if result[6] else None,
        'unique_cameras': result[7]
    }

    logging.info(f"Metriques calculees: {metrics}")
    return metrics
```

**Explication SQL :**

1. **COUNT(*)** : Total de pr√©dictions
2. **SUM(CASE...)** : Compte seulement les feux d√©tect√©s
3. **AVG(CASE...)** : Confiance moyenne UNIQUEMENT sur les d√©tections (ignore les "pas de feu")
4. **STDDEV** : √âcart-type (dispersion des confidences)
5. **AVG(inference_time_ms)** : Temps moyen d'inf√©rence
6. **COUNT(DISTINCT camera_name)** : Nombre de cam√©ras uniques

**Pourquoi CASE WHEN ?**
- On ne veut calculer la confiance moyenne QUE sur les d√©tections de feu
- Si on inclut les "pas de feu" (confidence = NULL), √ßa fausse les stats

### M√©thode detect_anomalies()

```python
def detect_anomalies(self, metrics):
    """
    D√©tecte les anomalies dans les m√©triques

    Args:
        metrics: Dictionnaire des m√©triques quotidiennes

    Returns:
        list: Liste des alertes d√©tect√©es
    """
    if metrics is None:
        return []

    alerts = []

    # ALERTE 1: Confiance moyenne trop basse
    if metrics['avg_confidence'] and metrics['avg_confidence'] < THRESHOLDS['min_avg_confidence']:
        alerts.append({
            'type': 'low_confidence',
            'message': f"Confiance moyenne trop basse: {metrics['avg_confidence']:.2f} < {THRESHOLDS['min_avg_confidence']}",
            'severity': 'critical',  # CRITIQUE = n√©cessite r√©entra√Ænement
            'value': metrics['avg_confidence'],
            'threshold': THRESHOLDS['min_avg_confidence']
        })

    # ALERTE 2: Confiance moyenne trop √©lev√©e (overfitting)
    if metrics['avg_confidence'] and metrics['avg_confidence'] > THRESHOLDS['max_avg_confidence']:
        alerts.append({
            'type': 'high_confidence',
            'message': f"Confiance moyenne anormalement elevee (possible overfitting): {metrics['avg_confidence']:.2f} > {THRESHOLDS['max_avg_confidence']}",
            'severity': 'warning',
            'value': metrics['avg_confidence'],
            'threshold': THRESHOLDS['max_avg_confidence']
        })

    # ALERTE 3: Nombre de pr√©dictions trop bas
    if metrics['total_predictions'] < THRESHOLDS['min_daily_predictions']:
        alerts.append({
            'type': 'low_predictions',
            'message': f"Nombre de predictions trop bas: {metrics['total_predictions']} < {THRESHOLDS['min_daily_predictions']}",
            'severity': 'warning',
            'value': metrics['total_predictions'],
            'threshold': THRESHOLDS['min_daily_predictions']
        })

    # ALERTE 4: Temps d'inf√©rence trop long
    if metrics['avg_inference_time_ms'] and metrics['avg_inference_time_ms'] > THRESHOLDS['max_inference_time_ms']:
        alerts.append({
            'type': 'slow_inference',
            'message': f"Temps d'inference trop long: {metrics['avg_inference_time_ms']:.0f}ms > {THRESHOLDS['max_inference_time_ms']}ms",
            'severity': 'warning',
            'value': metrics['avg_inference_time_ms'],
            'threshold': THRESHOLDS['max_inference_time_ms']
        })

    return alerts
```

**Explication :**
- V√©rifie chaque m√©trique contre les seuils
- Cr√©e une alerte pour chaque seuil d√©pass√©
- `severity` : 'critical' ou 'warning'
  - **critical** : D√©clenche potentiellement le r√©entra√Ænement
  - **warning** : Informe mais n'agit pas automatiquement

### M√©thode get_trend_analysis()

```python
def get_trend_analysis(self, days=7):
    """
    Analyse les tendances sur les N derniers jours

    Args:
        days: Nombre de jours √† analyser

    Returns:
        dict: Tendances (increasing/decreasing/stable)
    """
    self.cur.execute("""
        SELECT
            metric_date,
            avg_confidence,
            total_predictions,
            fire_detections,
            avg_inference_time_ms
        FROM daily_metrics
        WHERE metric_date >= CURRENT_DATE - INTERVAL '%s days'
        ORDER BY metric_date DESC
    """, (days,))

    results = self.cur.fetchall()

    if len(results) < 2:
        return None  # Pas assez de donn√©es

    trends = {
        'period_days': days,
        'avg_confidence_trend': self._calculate_trend([r[1] for r in results if r[1]]),
        'predictions_trend': self._calculate_trend([r[2] for r in results]),
        'fire_detections_trend': self._calculate_trend([r[3] for r in results]),
        'inference_time_trend': self._calculate_trend([r[4] for r in results if r[4]])
    }

    return trends

def _calculate_trend(self, values):
    """
    Calcule la tendance (hausse/baisse/stable)

    M√©thode: Compare la moyenne de la premi√®re moiti√© avec la deuxi√®me moiti√©
    """
    if len(values) < 2:
        return 'insufficient_data'

    first_half = sum(values[:len(values)//2]) / (len(values)//2)
    second_half = sum(values[len(values)//2:]) / (len(values) - len(values)//2)

    diff_percent = ((second_half - first_half) / first_half * 100) if first_half > 0 else 0

    if diff_percent > 10:
        return 'increasing'  # Hausse > 10%
    elif diff_percent < -10:
        return 'decreasing'  # Baisse > 10%
    else:
        return 'stable'      # Variation < 10%
```

**Explication de l'analyse de tendance :**

**M√©thode simple mais efficace :**
1. R√©cup√®re les 7 derniers jours
2. Divise en 2 moiti√©s (3.5 premiers jours vs 3.5 derniers jours)
3. Compare les moyennes
4. Si diff√©rence > 10% ‚Üí Tendance claire

**Exemple :**
- Jours 1-3 : confiance moyenne = 0.70
- Jours 4-7 : confiance moyenne = 0.60
- Diff√©rence : -14% ‚Üí **decreasing** ‚Üí ALERTE!

### M√©thode generate_report()

```python
def generate_report(self, metrics, alerts, trends):
    """
    G√©n√®re un rapport HTML pour email

    Args:
        metrics: M√©triques quotidiennes
        alerts: Liste des alertes
        trends: Tendances 7 jours

    Returns:
        str: HTML du rapport
    """
    if metrics is None:
        return "<p>Aucune donnee disponible pour generer un rapport.</p>"

    status_emoji = "üî¥" if alerts else "üü¢"

    html = f"""
    <html>
    <body style="font-family: Arial, sans-serif;">
        <h2>{status_emoji} Rapport de Monitoring du Modele - {metrics['metric_date']}</h2>

        <h3>Metriques Quotidiennes</h3>
        <table border="1" cellpadding="8" style="border-collapse: collapse;">
            <tr><td><b>Total predictions</b></td><td>{metrics['total_predictions']}</td></tr>
            <tr><td><b>Feux detectes</b></td><td>{metrics['fire_detections']}</td></tr>
            <tr><td><b>Cameras uniques</b></td><td>{metrics['unique_cameras']}</td></tr>
            <tr style="background-color: {'#ffcccc' if metrics['avg_confidence'] and metrics['avg_confidence'] < THRESHOLDS['min_avg_confidence'] else '#ccffcc'}">
                <td><b>Confiance moyenne</b></td>
                <td>{metrics['avg_confidence']:.2f if metrics['avg_confidence'] else 'N/A'}</td>
            </tr>
            <tr><td><b>Confiance min/max</b></td><td>{metrics['min_confidence']:.2f if metrics['min_confidence'] else 'N/A'} / {metrics['max_confidence']:.2f if metrics['max_confidence'] else 'N/A'}</td></tr>
            <tr><td><b>Temps inference moyen</b></td><td>{metrics['avg_inference_time_ms']:.0f}ms</td></tr>
        </table>
    """

    # ALERTES
    if alerts:
        html += "<h3 style='color: red;'>Alertes Detectees</h3><ul>"
        for alert in alerts:
            color = 'red' if alert['severity'] == 'critical' else 'orange'
            html += f"<li style='color: {color};'><b>{alert['type']}</b>: {alert['message']}</li>"
        html += "</ul>"
    else:
        html += "<p style='color: green;'><b>Aucune alerte - Modele fonctionne normalement</b></p>"

    # TENDANCES
    if trends:
        html += "<h3>Tendances (7 derniers jours)</h3><ul>"
        html += f"<li>Confiance: {trends['avg_confidence_trend']}</li>"
        html += f"<li>Predictions: {trends['predictions_trend']}</li>"
        html += f"<li>Detections feux: {trends['fire_detections_trend']}</li>"
        html += f"<li>Temps inference: {trends['inference_time_trend']}</li>"
        html += "</ul>"

    html += """
        <hr>
        <p style="color: gray; font-size: 12px;">
        Rapport genere automatiquement par le systeme de monitoring Fire Detection.
        </p>
    </body>
    </html>
    """

    return html
```

**Explication du rapport HTML :**

1. **Emoji de statut** : üü¢ si OK, üî¥ si alertes
2. **Tableau de m√©triques** : Mise en forme professionnelle
3. **Code couleur** :
   - Rouge si confiance trop basse (< 60%)
   - Vert sinon
4. **Section alertes** : Liste d√©taill√©e si probl√®mes
5. **Tendances** : Affiche l'√©volution sur 7 jours

**Ce rapport est envoy√© par email tous les jours √† 9h !**

---

# R√©entra√Ænement

## retraining/retrain_model.py

**Objectif :** R√©entra√Æner automatiquement le mod√®le YOLOv8 avec de nouvelles images annot√©es.

### Classe ModelRetrainer

```python
class ModelRetrainer:
    def __init__(self, base_model_path='model/weights/best.pt'):
        """
        Initialise le syst√®me de r√©entra√Ænement

        Args:
            base_model_path: Chemin vers le mod√®le actuel (sera utilis√© comme base)
        """
        self.base_model_path = base_model_path
        self.conn = psycopg2.connect(DATABASE_URL)
        self.cur = self.conn.cursor()
        self.s3 = boto3.client('s3')

        # Repertoires de travail
        self.work_dir = Path('retraining_workspace')
        self.dataset_dir = self.work_dir / 'dataset'
        self.images_dir = self.dataset_dir / 'images'
        self.labels_dir = self.dataset_dir / 'labels'
        self.train_dir = self.images_dir / 'train'
        self.val_dir = self.images_dir / 'val'
        self.train_labels_dir = self.labels_dir / 'train'
        self.val_labels_dir = self.labels_dir / 'val'

        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
```

**Explication de l'architecture des dossiers :**

```
retraining_workspace/
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/  (80% des images)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val/    (20% des images)
‚îÇ   ‚îú‚îÄ‚îÄ labels/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/  (fichiers .txt YOLO)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val/
‚îÇ   ‚îî‚îÄ‚îÄ data.yaml   (config YOLOv8)
‚îî‚îÄ‚îÄ runs/           (r√©sultats d'entra√Ænement)
```

**Format YOLO pour les labels :**
Chaque image `img_123.jpg` a un fichier `img_123.txt` :
```
0 0.5 0.5 0.2 0.3
```
- `0` : Classe (0 = fire)
- `0.5 0.5` : Centre de la bo√Æte (x, y) normalis√© (0-1)
- `0.2 0.3` : Largeur, hauteur normalis√©es (0-1)

### M√©thode check_if_retraining_needed()

```python
def check_if_retraining_needed(self):
    """
    V√©rifie si un r√©entra√Ænement est n√©cessaire

    Crit√®res:
    1. Alertes critiques r√©centes (7 jours) + 100 annotations
    2. OU 500+ annotations disponibles

    Returns:
        tuple: (should_retrain, reason, annotated_count)
    """
    # V√©rifier s'il y a des alertes critiques r√©centes
    self.cur.execute("""
        SELECT COUNT(*) FROM model_alerts
        WHERE severity = 'critical'
        AND created_at > NOW() - INTERVAL '7 days'
        AND resolved = FALSE
    """)
    critical_alerts = self.cur.fetchone()[0]

    # Compter les images annot√©es non utilis√©es
    self.cur.execute("""
        SELECT COUNT(*) FROM annotations
        WHERE used_for_training = FALSE
        AND is_correct IS NOT NULL
    """)
    annotated_count = self.cur.fetchone()[0]

    # D√âCISION
    if critical_alerts > 0 and annotated_count >= 100:
        return True, f"{critical_alerts} alerte(s) critique(s) detectee(s)", annotated_count
    elif annotated_count >= 500:
        return True, f"{annotated_count} nouvelles images annotees disponibles", annotated_count
    else:
        return False, f"Pas assez d'images annotees ({annotated_count}/100 minimum)", annotated_count
```

**Explication de la logique :**

**Cas 1 : R√©entra√Ænement urgent**
- Alertes critiques (confiance < 60%)
- ET au moins 100 images annot√©es
- ‚Üí Le mod√®le d√©grade, on r√©entra√Æne imm√©diatement

**Cas 2 : R√©entra√Ænement pr√©ventif**
- 500+ images annot√©es disponibles
- ‚Üí On am√©liore proactivement le mod√®le

**Cas 3 : Pas de r√©entra√Ænement**
- Pas d'alertes critiques
- ET moins de 100 annotations
- ‚Üí On attend plus de donn√©es

### M√©thode prepare_dataset()

```python
def prepare_dataset(self):
    """
    Pr√©pare le dataset pour l'entra√Ænement
    1. T√©l√©charge images depuis S3
    2. Cr√©e les fichiers labels YOLO
    3. Split train/val (80/20)

    Returns:
        tuple: (data_yaml_path, train_count, val_count)
    """
    logging.info("Preparation du dataset...")

    # 1. CR√âER LES R√âPERTOIRES
    for dir_path in [self.train_dir, self.val_dir, self.train_labels_dir, self.val_labels_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)

    # 2. R√âCUP√âRER LES ANNOTATIONS
    self.cur.execute("""
        SELECT a.id, a.image_id, a.corrected_label, a.corrected_bbox,
               a.is_correct, i.s3_path, i.camera_name,
               mp.fire_detected, mp.confidence, mp.bbox
        FROM annotations a
        JOIN images i ON a.image_id = i.id
        LEFT JOIN model_predictions mp ON a.prediction_id = mp.id
        WHERE a.used_for_training = FALSE
        AND a.is_correct IS NOT NULL
        ORDER BY a.annotated_at
    """)

    annotations = self.cur.fetchall()
    total = len(annotations)

    if total < 100:
        raise Exception(f"Pas assez d'annotations ({total}/100 minimum)")

    logging.info(f"Preparation de {total} images annotees...")

    # 3. SPLIT TRAIN/VAL (80/20)
    split_idx = int(total * 0.8)

    # 4. TRAITER CHAQUE ANNOTATION
    for idx, annot in enumerate(annotations):
        (annot_id, image_id, corrected_label, corrected_bbox, is_correct,
         s3_path, camera_name, fire_detected, confidence, bbox) = annot

        # D√©terminer si train ou val
        is_train = idx < split_idx
        img_dir = self.train_dir if is_train else self.val_dir
        lbl_dir = self.train_labels_dir if is_train else self.val_labels_dir

        # 5. T√âL√âCHARGER L'IMAGE DEPUIS S3
        image_filename = f"img_{image_id}.jpg"
        local_image_path = img_dir / image_filename

        try:
            self.s3.download_file(S3_BUCKET_NAME, s3_path, str(local_image_path))
        except Exception as e:
            logging.error(f"Erreur telechargement image {image_id}: {e}")
            continue

        # 6. CR√âER LE FICHIER LABEL YOLO
        label_filename = f"img_{image_id}.txt"
        local_label_path = lbl_dir / label_filename

        # Utiliser la bbox corrig√©e si disponible, sinon celle pr√©dite
        final_bbox = corrected_bbox if corrected_bbox else bbox

        # 7. √âCRIRE LE LABEL
        if final_bbox and (is_correct or corrected_label == 'fire'):
            with open(local_label_path, 'w') as f:
                class_id = 0  # fire
                if isinstance(final_bbox, dict):
                    x, y, w, h = final_bbox.get('x', 0), final_bbox.get('y', 0), final_bbox.get('w', 0), final_bbox.get('h', 0)
                else:
                    x, y, w, h = final_bbox[0], final_bbox[1], final_bbox[2], final_bbox[3]
                f.write(f"{class_id} {x} {y} {w} {h}\n")
        else:
            # Pas de feu ou faux positif ‚Üí fichier label vide
            local_label_path.touch()

    # 8. CR√âER LE FICHIER data.yaml
    data_yaml = {
        'path': str(self.dataset_dir.absolute()),
        'train': 'images/train',
        'val': 'images/val',
        'nc': 1,  # Nombre de classes
        'names': ['fire']  # Noms des classes
    }

    data_yaml_path = self.dataset_dir / 'data.yaml'
    with open(data_yaml_path, 'w') as f:
        yaml.dump(data_yaml, f)

    logging.info(f"Dataset prepare: {split_idx} train, {total - split_idx} val")
    return data_yaml_path, split_idx, total - split_idx
```

**Explication d√©taill√©e :**

**√âtape 2 : Requ√™te SQL complexe**
- `JOIN` : R√©cup√®re les infos depuis 3 tables
  - `annotations` : Corrections manuelles
  - `images` : M√©tadonn√©es et S3 path
  - `model_predictions` : Pr√©dictions originales
- `WHERE used_for_training = FALSE` : Uniquement les nouvelles annotations
- `AND is_correct IS NOT NULL` : Annotations valid√©es (pas en attente)

**√âtape 3 : Split 80/20**
- 80% pour l'entra√Ænement (le mod√®le apprend)
- 20% pour la validation (mesurer la performance)
- Important : PAS de m√©lange al√©atoire ici (ordre chronologique)

**√âtape 6-7 : Logique des labels**
- Si annotation corrig√©e ‚Üí Utiliser la bbox corrig√©e
- Sinon ‚Üí Utiliser la bbox originale du mod√®le
- Si faux positif ‚Üí Fichier vide (indique "pas de feu")

**√âtape 8 : data.yaml**
- Fichier de configuration requis par YOLOv8
- Indique o√π sont les donn√©es et combien de classes

### M√©thode train_model()

```python
def train_model(self, data_yaml_path, epochs=50, batch_size=16, img_size=960, learning_rate=0.001):
    """
    Entra√Æne le mod√®le YOLOv8 avec fine-tuning

    Args:
        data_yaml_path: Chemin vers data.yaml
        epochs: Nombre d'√©poques (d√©faut 50)
        batch_size: Taille des batchs (d√©faut 16)
        img_size: Taille des images (d√©faut 960)
        learning_rate: Taux d'apprentissage (d√©faut 0.001)

    Returns:
        dict: R√©sultats d'entra√Ænement (metrics, paths, etc.)
    """
    logging.info("Demarrage de l'entrainement...")

    version_name = f"fire_model_v{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    # D√âMARRER MLFLOW RUN
    with mlflow.start_run(run_name=version_name) as run:
        mlflow_run_id = run.info.run_id

        # Logger les hyperparam√®tres
        mlflow.log_param("base_model", self.base_model_path)
        mlflow.log_param("epochs", epochs)
        mlflow.log_param("batch_size", batch_size)
        mlflow.log_param("img_size", img_size)
        mlflow.log_param("learning_rate", learning_rate)

        # 1. CHARGER LE MOD√àLE DE BASE
        model = YOLO(self.base_model_path)

        # 2. ENTRA√éNER
        training_start = datetime.now()

        results = model.train(
            data=str(data_yaml_path),
            epochs=epochs,
            batch=batch_size,
            imgsz=img_size,
            lr0=learning_rate,
            project=str(self.work_dir / 'runs'),
            name=version_name,
            exist_ok=True,
            verbose=True
        )

        training_end = datetime.now()
        training_duration = (training_end - training_start).total_seconds() / 60

        # 3. VALIDER LE MOD√àLE
        val_results = model.val()

        # 4. EXTRAIRE LES M√âTRIQUES
        precision = float(val_results.box.p.mean()) if hasattr(val_results.box, 'p') else 0.0
        recall = float(val_results.box.r.mean()) if hasattr(val_results.box, 'r') else 0.0
        map50 = float(val_results.box.map50) if hasattr(val_results.box, 'map50') else 0.0
        map50_95 = float(val_results.box.map) if hasattr(val_results.box, 'map') else 0.0

        # 5. LOGGER DANS MLFLOW
        mlflow.log_metric("precision", precision)
        mlflow.log_metric("recall", recall)
        mlflow.log_metric("map50", map50)
        mlflow.log_metric("map50_95", map50_95)

        # 6. SAUVEGARDER LE MOD√àLE
        model_path = self.work_dir / 'runs' / version_name / 'weights' / 'best.pt'
        mlflow.log_artifact(str(model_path))

        logging.info(f"Entrainement termine - Precision: {precision:.3f}, Recall: {recall:.3f}, mAP50: {map50:.3f}")

        return {
            'version_name': version_name,
            'mlflow_run_id': mlflow_run_id,
            'model_path': str(model_path),
            'precision': precision,
            'recall': recall,
            'map50': map50,
            'map50_95': map50_95,
            'training_duration': training_duration,
            'training_start': training_start,
            'training_end': training_end
        }
```

**Explication d√©taill√©e :**

**1. MLflow Run**
- Cr√©e un "run" pour tracker cet entra√Ænement
- Tous les param√®tres et m√©triques seront associ√©s √† ce run
- Visible dans l'interface MLflow (http://localhost:5001)

**2. Fine-tuning**
- On part du mod√®le actuel (base_model_path)
- Le mod√®le a d√©j√† √©t√© entra√Æn√© sur Pyro-SDIS
- On l'affine avec les nouvelles donn√©es annot√©es

**3. Param√®tres d'entra√Ænement**
- `epochs=30` : Moins que l'entra√Ænement initial (50) car c'est du fine-tuning
- `batch_size=16` : Nombre d'images par batch
- `img_size=960` : DOIT √™tre identique √† l'entra√Ænement initial
- `lr0=0.001` : Learning rate (taux d'apprentissage)

**4. M√©triques**
- **Precision** : Sur 100 d√©tections "feu", combien sont vraies?
- **Recall** : Sur 100 vrais feux, combien sont d√©tect√©s?
- **mAP50** : Mean Average Precision (IoU‚â•0.5)
- **mAP50-95** : mAP moyen sur plusieurs IoU

**Exemple :**
- Precision = 0.85 ‚Üí 85% des d√©tections sont correctes (15% faux positifs)
- Recall = 0.75 ‚Üí On d√©tecte 75% des feux r√©els (25% manqu√©s)

### M√©thode compare_with_baseline()

```python
def compare_with_baseline(self, new_version_name):
    """
    Compare la nouvelle version avec la version actuellement d√©ploy√©e

    Args:
        new_version_name: Nom de la nouvelle version

    Returns:
        tuple: (should_deploy, improvement_percent, comparison_details)
    """
    # 1. R√âCUP√âRER LA VERSION ACTUELLEMENT D√âPLOY√âE
    self.cur.execute("""
        SELECT version_name, precision, recall, map50
        FROM model_versions
        WHERE deployed = TRUE
        ORDER BY deployed_at DESC
        LIMIT 1
    """)

    baseline = self.cur.fetchone()

    if not baseline:
        logging.info("Pas de baseline deployee, deploiement automatique")
        return True, 100.0, "Premiere version"

    baseline_name, baseline_precision, baseline_recall, baseline_map50 = baseline

    # 2. R√âCUP√âRER LES M√âTRIQUES DE LA NOUVELLE VERSION
    self.cur.execute("""
        SELECT precision, recall, map50
        FROM model_versions
        WHERE version_name = %s
    """, (new_version_name,))

    new_metrics = self.cur.fetchone()
    new_precision, new_recall, new_map50 = new_metrics

    # 3. CALCULER L'AM√âLIORATION
    improvement = ((new_map50 - baseline_map50) / baseline_map50 * 100) if baseline_map50 > 0 else 0

    # 4. D√âCISION: D√âPLOYER SI AM√âLIORATION ‚â• 2%
    should_deploy = improvement >= 2.0 or (new_precision > baseline_precision and new_recall > baseline_recall)

    # 5. SAUVEGARDER LA COMPARAISON
    self.cur.execute("""
        INSERT INTO model_comparisons
        (old_version, new_version, old_precision, new_precision, old_recall,
         new_recall, old_map50, new_map50, improvement_percent, decision, decision_reason)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """, (
        baseline_name,
        new_version_name,
        baseline_precision,
        new_precision,
        baseline_recall,
        new_recall,
        baseline_map50,
        new_map50,
        improvement,
        'deploy' if should_deploy else 'rollback',
        f"Amelioration: {improvement:.1f}%" if should_deploy else "Pas assez d'amelioration"
    ))
    self.conn.commit()

    logging.info(f"Comparaison: Baseline {baseline_name} (mAP50={baseline_map50:.3f}) vs {new_version_name} (mAP50={new_map50:.3f})")
    logging.info(f"Amelioration: {improvement:.1f}% - Decision: {'DEPLOYER' if should_deploy else 'ROLLBACK'}")

    return should_deploy, improvement, {
        'baseline_name': baseline_name,
        'baseline_map50': baseline_map50,
        'new_map50': new_map50
    }
```

**Explication de la logique de d√©cision :**

**Crit√®re principal : mAP50**
- C'est la m√©trique la plus fiable pour YOLO
- Combine pr√©cision ET rappel
- Si am√©lioration ‚â• 2% ‚Üí D√âPLOYER

**Crit√®re secondaire : Pr√©cision ET Rappel**
- Si les DEUX s'am√©liorent ‚Üí D√âPLOYER
- M√™me si mAP50 < 2%

**Exemple de d√©cision :**

**Cas 1 : D√©ploiement**
```
Baseline: mAP50 = 0.77
Nouvelle: mAP50 = 0.79
Am√©lioration: +2.6% ‚Üí D√âPLOYER ‚úÖ
```

**Cas 2 : Rollback**
```
Baseline: mAP50 = 0.77
Nouvelle: mAP50 = 0.771
Am√©lioration: +0.1% ‚Üí ROLLBACK ‚ùå (pas assez)
```

**Cas 3 : D√©ploiement (crit√®re secondaire)**
```
Baseline: Precision=0.77, Recall=0.76
Nouvelle: Precision=0.78, Recall=0.77
Les deux s'am√©liorent ‚Üí D√âPLOYER ‚úÖ
```

**Pourquoi seuil √† 2% ?**
- √âvite les d√©ploiements pour variations mineures
- 2% = Am√©lioration significative et mesurable
- R√©duit les risques de r√©gression

### M√©thode deploy_model()

```python
def deploy_model(self, version_name, model_path):
    """
    D√©ploie la nouvelle version du mod√®le en production

    Args:
        version_name: Nom de la version √† d√©ployer
        model_path: Chemin vers le fichier .pt
    """
    logging.info(f"Deploiement de {version_name}...")

    production_model_path = Path(self.base_model_path)
    production_model_path.parent.mkdir(parents=True, exist_ok=True)

    # 1. BACKUP DE L'ANCIEN MOD√àLE
    if production_model_path.exists():
        backup_path = production_model_path.parent / f"best_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pt"
        shutil.copy(production_model_path, backup_path)
        logging.info(f"Backup de l'ancien modele: {backup_path}")

    # 2. COPIER LE NOUVEAU MOD√àLE
    shutil.copy(model_path, production_model_path)

    # 3. MARQUER COMME D√âPLOY√â DANS LA BASE
    # D'abord, d√©marquer l'ancien
    self.cur.execute("""
        UPDATE model_versions
        SET deployed = FALSE
        WHERE deployed = TRUE
    """)

    # Puis marquer le nouveau
    self.cur.execute("""
        UPDATE model_versions
        SET deployed = TRUE, deployed_at = NOW()
        WHERE version_name = %s
    """, (version_name,))

    self.conn.commit()

    logging.info(f"Modele {version_name} deploye avec succes!")
```

**Explication du process de d√©ploiement :**

**√âtape 1 : Backup**
- Copie l'ancien mod√®le avec timestamp
- Permet un rollback manuel si probl√®me
- Exemple : `best_backup_20260109_143022.pt`

**√âtape 2 : Remplacement**
- Copie le nouveau mod√®le vers `model/weights/best.pt`
- √Ä partir de maintenant, c'est CE mod√®le qui sera utilis√©

**√âtape 3 : Base de donn√©es**
- D√©marque toutes les anciennes versions
- Marque la nouvelle comme d√©ploy√©e
- Historique complet conserv√©

**IMPORTANT :**
- Le d√©ploiement est **imm√©diat**
- Prochaine inf√©rence = nouveau mod√®le
- Pas besoin de red√©marrer Airflow

---

## retraining/annotation_tools.py

**Objectif :** Outils pour annoter manuellement les pr√©dictions.

### Classe AnnotationManager

```python
class AnnotationManager:
    def __init__(self):
        """Initialise le gestionnaire d'annotations"""
        self.conn = psycopg2.connect(DATABASE_URL)
        self.cur = self.conn.cursor()
```

### M√©thode get_predictions_to_review()

```python
def get_predictions_to_review(self, limit=50, fire_only=False):
    """
    R√©cup√®re les pr√©dictions qui n√©cessitent une r√©vision

    Args:
        limit: Nombre max de pr√©dictions
        fire_only: True pour ne r√©cup√©rer que les d√©tections de feu

    Returns:
        list: Liste de pr√©dictions √† reviewer
    """
    fire_filter = "AND mp.fire_detected = TRUE" if fire_only else ""

    self.cur.execute(f"""
        SELECT mp.id, mp.image_id, mp.camera_name, mp.fire_detected,
               mp.confidence, mp.bbox, i.s3_path, mp.prediction_timestamp
        FROM model_predictions mp
        JOIN images i ON mp.image_id = i.id
        LEFT JOIN annotations a ON mp.id = a.prediction_id
        WHERE a.id IS NULL  -- Pas encore annot√©e
        {fire_filter}
        ORDER BY mp.prediction_timestamp DESC
        LIMIT %s
    """, (limit,))

    predictions = []
    for row in self.cur.fetchall():
        predictions.append({
            'prediction_id': row[0],
            'image_id': row[1],
            'camera_name': row[2],
            'fire_detected': row[3],
            'confidence': row[4],
            'bbox': row[5],
            's3_path': row[6],
            'timestamp': row[7]
        })

    return predictions
```

**Explication :**
- `LEFT JOIN annotations` : R√©cup√®re aussi les pr√©dictions sans annotation
- `WHERE a.id IS NULL` : Filtre les non-annot√©es
- `fire_only` : Utile pour se concentrer sur les faux positifs

### M√©thode annotate_prediction()

```python
def annotate_prediction(self, prediction_id, is_correct, corrected_label=None,
                      corrected_bbox=None, notes=None, annotated_by='manual'):
    """
    Annote une pr√©diction

    Args:
        prediction_id: ID de la pr√©diction
        is_correct: True si la pr√©diction est correcte, False sinon
        corrected_label: 'fire' ou 'no_fire' si correction n√©cessaire
        corrected_bbox: [x, y, w, h] si bbox incorrecte
        notes: Notes optionnelles
        annotated_by: Qui a annot√© (d√©faut: 'manual')

    Returns:
        int: ID de l'annotation cr√©√©e
    """
    self.cur.execute("""
        INSERT INTO annotations
        (prediction_id, image_id, annotation_type, is_correct, corrected_label,
         corrected_bbox, notes, annotated_by)
        SELECT %s, mp.image_id,
               CASE WHEN %s THEN 'validation' ELSE 'correction' END,
               %s, %s, %s, %s, %s
        FROM model_predictions mp
        WHERE mp.id = %s
        RETURNING id
    """, (
        prediction_id,
        is_correct,
        is_correct,
        corrected_label,
        psycopg2.extras.Json(corrected_bbox) if corrected_bbox else None,
        notes,
        annotated_by,
        prediction_id
    ))

    self.conn.commit()
    annotation_id = self.cur.fetchone()[0]

    logging.info(f"Annotation creee: ID={annotation_id}, prediction={prediction_id}, is_correct={is_correct}")
    return annotation_id
```

**Explication :**
- `annotation_type` : 'validation' si correct, 'correction' sinon
- `corrected_label` : Uniquement si pr√©diction incorrecte
- `corrected_bbox` : Uniquement si bbox mal plac√©e

**Exemples d'usage :**

**Cas 1 : Pr√©diction correcte**
```python
annotate_prediction(123, is_correct=True)
# Le mod√®le a bien d√©tect√© un feu
```

**Cas 2 : Faux positif**
```python
annotate_prediction(456, is_correct=False, corrected_label='no_fire', notes='Reflet soleil')
# Le mod√®le a d√©tect√© un feu mais c'√©tait un reflet
```

**Cas 3 : Bounding box incorrecte**
```python
annotate_prediction(789, is_correct=False, corrected_bbox=[0.6, 0.4, 0.2, 0.3], notes='Bbox trop petite')
# Le mod√®le a d√©tect√© le feu mais la bo√Æte n'encadre pas bien les flammes
```

### M√©thode get_annotation_stats()

```python
def get_annotation_stats(self):
    """
    R√©cup√®re les statistiques d'annotation

    Returns:
        dict: Statistiques compl√®tes
    """
    self.cur.execute("""
        SELECT
            COUNT(*) as total,
            SUM(CASE WHEN is_correct THEN 1 ELSE 0 END) as correct,
            SUM(CASE WHEN NOT is_correct THEN 1 ELSE 0 END) as incorrect,
            SUM(CASE WHEN used_for_training THEN 1 ELSE 0 END) as used_for_training,
            SUM(CASE WHEN NOT used_for_training AND is_correct IS NOT NULL THEN 1 ELSE 0 END) as ready_for_training
        FROM annotations
    """)

    row = self.cur.fetchone()

    return {
        'total': row[0],
        'correct': row[1],
        'incorrect': row[2],
        'used_for_training': row[3],
        'ready_for_training': row[4]  # Annotations valid√©es mais pas encore utilis√©es
    }
```

**Explication :**
- `ready_for_training` : Annotations pr√™tes pour le r√©entra√Ænement
- Quand ce nombre atteint 100 ‚Üí On peut r√©entra√Æner

---

# Orchestration Airflow

## dags/fire_detection_workflow.py

**Objectif :** DAG principal qui orchestre scraping ‚Üí inference ‚Üí alertes.

### Configuration du DAG

```python
default_args = {
    'owner': 'axel',
    'retries': 1,
    'retry_delay': timedelta(minutes=1),
    'start_date': datetime(2024, 1, 1),
    'catchup': False,  # Ne pas rattraper les ex√©cutions manqu√©es
    'email_on_failure': False,
}

with DAG(
    'fire_detection_pipeline',
    default_args=default_args,
    description='Pipeline de d√©tection incendie',
    schedule_interval='*/15 * * * *',  # Toutes les 15 minutes
    catchup=False
) as dag:
```

**Explication :**
- `owner` : Propri√©taire du DAG
- `retries=1` : R√©essaie 1 fois si √©chec
- `retry_delay` : Attend 1 minute avant de r√©essayer
- `catchup=False` : **IMPORTANT** - Ne pas rattraper le pass√©
- `schedule_interval='*/15 * * * *'` : Expression cron pour "toutes les 15 minutes"

**Format cron :**
```
*/15 * * * *
 ‚îÇ   ‚îÇ ‚îÇ ‚îÇ ‚îÇ
 ‚îÇ   ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ Jour de la semaine (0-6, 0=dimanche)
 ‚îÇ   ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Mois (1-12)
 ‚îÇ   ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Jour du mois (1-31)
 ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Heure (0-23)
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄMinute (0-59)

*/15 = Toutes les 15 minutes
```

### T√¢che 1 : Scraping

```python
def task_scrape_images(**context):
    """
    T√¢che 1: Scraper les cam√©ras

    Steps:
    1. Initialise le scraper
    2. D√©marre le navigateur Chrome
    3. Scrape toutes les 165 cam√©ras
    4. Upload sur S3 + Enregistre dans Neon
    5. Ferme le navigateur
    """
    print("D√©but du scraping...")
    from scraper import AlertWildfireScraper

    scraper = AlertWildfireScraper()
    scraper.start()
    scraper.scrape_all()  # Toutes les 165 cam√©ras
    scraper.stop()
    print("Scraping termin√©.")
```

**Explication :**
- Fonction Python appel√©e par Airflow
- `**context` : Airflow passe des infos contextuelles (date d'ex√©cution, etc.)
- Import local : `from scraper import...` (√©vite import au niveau module)

### T√¢che 2 : Inf√©rence + Email

```python
def task_run_inference(**context):
    """
    T√¢che 2: Analyser les images + Envoyer alertes

    Steps:
    1. R√©cup√®re les images en attente (status='NEW')
    2. Pour chaque image:
       a. T√©l√©charge depuis S3
       b. Inf√©rence YOLOv8 (avec logging monitoring auto)
       c. Si feu d√©tect√© ‚Üí Email d'alerte
       d. Met √† jour la base
    """
    print("D√©but de l'analyse IA...")

    import sys
    sys.path.insert(0, '/opt/airflow')
    from model.inference import FireDetector

    db = DatabaseManager()
    images = db.get_pending_images()  # Toutes les images en attente

    if not images:
        print("Aucune image en attente.")
        return

    # Initialiser le d√©tecteur (qui va auto-logger dans Neon)
    detector = FireDetector(model_path='/opt/airflow/model/weights/best.pt')

    s3 = boto3.client('s3')
    bucket = os.getenv("S3_BUCKET_NAME")

    for img in images:
        local_path = f"/tmp/{img['id']}.png"

        try:
            # 1. T√âL√âCHARGER DEPUIS S3
            s3.download_file(bucket, img['s3_path'], local_path)

            # 2. PR√âDICTION AVEC AUTO-LOGGING
            detections = detector.predict(
                image_path=local_path,
                conf_threshold=0.4,
                image_id=img['id'],
                batch_id=img['batch_id'],
                camera_name=img['camera_name'],
                s3_path=img['s3_path']
            )

            is_fire = len(detections) > 0
            conf = detections[0]['confidence'] if detections else 0.0
            bbox = detections[0]['bbox'] if detections else []

            # 3. METTRE √Ä JOUR LA BASE
            db.update_prediction(img['id'], is_fire, conf, bbox)

            # 4. ENVOYER EMAIL SI FEU D√âTECT√â
            if is_fire and conf > 0.4:
                print(f"FEU DETECTE (ID: {img['id']}) ! Envoi mail...")

                subject = f"ALERTE INCENDIE : {img['camera_name']}"
                html_content = f"""
                <h3>FEU DETECTE PAR LE MODELE</h3>
                <p><b>Camera :</b> {img['camera_name']}</p>
                <p><b>Confiance IA :</b> {conf:.2f} ({(conf*100):.0f}%)</p>
                <p><b>ID Image :</b> {img['id']}</p>
                <p><b>Batch ID :</b> {img['batch_id']}</p>
                <hr>
                <p><i>Ceci est une alerte automatique g√©n√©r√©e par Airflow + MLflow.</i></p>
                <p><i>Pr√©diction logg√©e dans Neon pour monitoring.</i></p>
                """

                send_email(to=['axel.vilamot@gmail.com'], subject=subject, html_content=html_content)
                print("Mail envoy√© via Airflow Backend.")

            os.remove(local_path)

        except Exception as e:
            print(f"Erreur sur l'image {img['id']}: {e}")

    db.close()
    print(f"Analyse termin√©e - {len(images)} images analys√©es et logg√©es dans Neon")
```

**Explication d√©taill√©e :**

**Path dans Docker**
- `/opt/airflow` : R√©pertoire racine dans le container
- √âquivalent √† votre dossier local `Fire_detection/`

**Boucle sur les images**
- Traite TOUTES les images en attente
- Si 100 images ‚Üí 100 inf√©rences
- Dur√©e totale ‚âà 50 secondes (500ms/image)

**Email d'alerte**
- `send_email()` : Fonction Airflow int√©gr√©e
- Utilise la config SMTP du .env
- Email HTML format√©

**Gestion m√©moire**
- `os.remove(local_path)` : Supprime l'image temporaire
- √âvite de saturer `/tmp` dans le container

### D√©finition du DAG

```python
with DAG(...) as dag:
    scrape_task = PythonOperator(
        task_id='scrape_cameras',
        python_callable=task_scrape_images
    )

    inference_task = PythonOperator(
        task_id='analyze_images',
        python_callable=task_run_inference
    )

    # D√âFINIR L'ORDRE D'EX√âCUTION
    scrape_task >> inference_task  # Scraping PUIS inference
```

**Explication de l'op√©rateur >>**
- D√©finit les d√©pendances entre t√¢ches
- `scrape_task >> inference_task` = "scrape AVANT inference"
- Airflow attend que scrape_task termine avant de lancer inference_task

**Visualisation dans Airflow :**
```
[scrape_cameras] ‚Üí [analyze_images]
```

---

## dags/monitor_model.py

**Objectif :** DAG pour le monitoring quotidien du mod√®le.

### Configuration

```python
with DAG(
    'model_monitoring_daily',
    default_args=default_args,
    description='Monitoring quotidien du modele de detection de feu',
    schedule_interval='0 9 * * *',  # Tous les jours √† 9h00 du matin
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['monitoring', 'model', 'fire_detection'],
) as dag:
```

**Explication :**
- `schedule_interval='0 9 * * *'` : Cron pour "9h tous les jours"
- `tags` : Pour filtrer dans l'interface Airflow

### T√¢che 1 : Calculer les m√©triques

```python
def calculate_and_save_metrics(**context):
    """
    Calcule les m√©triques quotidiennes et les sauvegarde
    """
    monitor = ModelMonitor()

    try:
        # Calculer les m√©triques d'hier
        metrics = monitor.calculate_daily_metrics()

        if metrics is None:
            print("Aucune prediction hier, pas de metriques a calculer")
            context['ti'].xcom_push(key='metrics', value=None)
            return

        # Sauvegarder les m√©triques
        monitor.save_daily_metrics(metrics)

        # Passer les m√©triques au contexte pour la prochaine t√¢che
        context['ti'].xcom_push(key='metrics', value=metrics)

        print(f"Metriques calculees et sauvegardees: {metrics}")

    finally:
        monitor.close()
```

**Explication de XCom :**
- `xcom_push` : Passe des donn√©es entre t√¢ches Airflow
- `context['ti']` : TaskInstance (instance de la t√¢che)
- Les m√©triques seront r√©cup√©r√©es par la t√¢che suivante avec `xcom_pull`

### T√¢che 2 : D√©tecter les anomalies

```python
def detect_and_alert(**context):
    """
    D√©tecte les anomalies dans les m√©triques et cr√©e des alertes
    """
    # R√©cup√©rer les m√©triques de la t√¢che pr√©c√©dente
    metrics = context['ti'].xcom_pull(key='metrics', task_ids='calculate_metrics')

    if metrics is None:
        print("Pas de metriques, pas d'analyse d'anomalies")
        context['ti'].xcom_push(key='alerts', value=[])
        return

    monitor = ModelMonitor()

    try:
        # D√©tecter les anomalies
        alerts = monitor.detect_anomalies(metrics)

        if alerts:
            print(f"ALERTE: {len(alerts)} anomalie(s) detectee(s)")
            for alert in alerts:
                print(f"  - {alert['message']}")

            # Sauvegarder les alertes
            monitor.save_alerts(alerts)
        else:
            print("Aucune anomalie detectee - Modele fonctionne normalement")

        # Passer les alertes au contexte
        context['ti'].xcom_push(key='alerts', value=alerts)

    finally:
        monitor.close()
```

**Explication :**
- R√©cup√®re les m√©triques avec `xcom_pull`
- D√©tecte les anomalies
- Sauvegarde dans `model_alerts`
- Passe les alertes √† la t√¢che suivante

### T√¢che 3 : Envoyer le rapport

```python
def generate_and_send_report(**context):
    """
    G√©n√®re un rapport HTML et l'envoie par email
    """
    metrics = context['ti'].xcom_pull(key='metrics', task_ids='calculate_metrics')
    alerts = context['ti'].xcom_pull(key='alerts', task_ids='detect_anomalies')

    if metrics is None:
        print("Pas de metriques, pas de rapport a envoyer")
        return

    monitor = ModelMonitor()

    try:
        # Analyse des tendances
        trends = monitor.get_trend_analysis(days=7)

        # G√©n√©rer le rapport HTML
        html_report = monitor.generate_report(metrics, alerts, trends)

        # Pr√©parer le sujet de l'email
        if alerts:
            critical_alerts = [a for a in alerts if a['severity'] == 'critical']
            if critical_alerts:
                subject = f"[CRITIQUE] Alerte Monitoring Modele - {metrics['metric_date']}"
            else:
                subject = f"[ATTENTION] Alerte Monitoring Modele - {metrics['metric_date']}"
        else:
            subject = f"[OK] Rapport Monitoring Modele - {metrics['metric_date']}"

        # Envoyer l'email
        send_email(
            to=['axel.vilamot@gmail.com'],
            subject=subject,
            html_content=html_report
        )

        print(f"Rapport envoye a axel.vilamot@gmail.com")

    finally:
        monitor.close()
```

**Explication :**
- R√©cup√®re m√©triques ET alertes
- Calcule les tendances
- G√©n√®re HTML
- Adapte le sujet selon la gravit√©
- Envoie l'email

### Ordre d'ex√©cution

```python
calculate_metrics_task >> detect_anomalies_task >> send_report_task
```

**Visualisation :**
```
[calculate_metrics] ‚Üí [detect_anomalies] ‚Üí [send_report]
```

---

## dags/retrain_workflow.py

**Objectif :** DAG pour le r√©entra√Ænement automatique (d√©clenchement manuel).

### Configuration

```python
with DAG(
    'model_retraining',
    default_args=default_args,
    description='Reentrainement automatique du modele de detection de feu',
    schedule_interval=None,  # D√©clenchement manuel uniquement
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['retraining', 'model', 'fire_detection'],
) as dag:
```

**Explication :**
- `schedule_interval=None` : **PAS d'ex√©cution automatique**
- Doit √™tre d√©clench√© manuellement depuis l'interface Airflow
- Ou d√©clench√© programmatiquement si alertes critiques

### T√¢che 1 : V√©rifier si r√©entra√Ænement n√©cessaire

```python
def check_retrain_needed(**context):
    """
    V√©rifie si un r√©entra√Ænement est n√©cessaire
    Retourne le nom de la prochaine t√¢che (branch)
    """
    retrainer = ModelRetrainer()

    try:
        should_retrain, reason, count = retrainer.check_if_retraining_needed()

        context['ti'].xcom_push(key='should_retrain', value=should_retrain)
        context['ti'].xcom_push(key='reason', value=reason)
        context['ti'].xcom_push(key='annotated_count', value=count)

        print(f"Verification: should_retrain={should_retrain}, reason={reason}, count={count}")

        if should_retrain:
            # Cr√©er le trigger
            trigger_id = retrainer.create_retrain_trigger('automatic', reason, count)
            context['ti'].xcom_push(key='trigger_id', value=trigger_id)
            return 'prepare_dataset_task'  # Passe √† l'√©tape suivante
        else:
            return 'skip_retrain_task'  # Skip tout le pipeline

    finally:
        retrainer.close()
```

**Explication de BranchPythonOperator :**
- Permet de **choisir dynamiquement** la prochaine t√¢che
- Si pas assez d'annotations ‚Üí Skip tout
- Si conditions OK ‚Üí Continue le pipeline

### Workflow complet

```python
# T√¢che de branchement
check_retrain = BranchPythonOperator(
    task_id='check_retrain_needed',
    python_callable=check_retrain_needed,
    provide_context=True,
)

# Chemin 1: R√©entra√Ænement
prepare_dataset = PythonOperator(task_id='prepare_dataset_task', ...)
train_model = PythonOperator(task_id='train_model_task', ...)
validate_and_compare = BranchPythonOperator(task_id='validate_and_compare', ...)
deploy_model = PythonOperator(task_id='deploy_model_task', ...)

# Chemin 2: Skip
skip_retrain = EmptyOperator(task_id='skip_retrain_task')

# Flux d'ex√©cution
check_retrain >> [prepare_dataset, skip_retrain]
prepare_dataset >> train_model >> validate_and_compare
validate_and_compare >> [deploy_model, skip_deploy]
[deploy_model, skip_deploy, skip_retrain] >> cleanup >> send_report
```

**Visualisation :**

```
                    ‚îå‚îÄ‚îÄ> skip_retrain ‚îÄ‚îÄ‚îê
                    ‚îÇ                    ‚îÇ
check_retrain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                    ‚îú‚îÄ‚îÄ> cleanup ‚îÄ‚îÄ> send_report
                    ‚îÇ                    ‚îÇ
                    ‚îî‚îÄ‚îÄ> prepare_dataset ‚îÄ‚îÄ> train_model ‚îÄ‚îÄ> validate ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ> deploy ‚îÄ‚îÄ‚îò
                                                                         ‚îî‚îÄ‚îÄ> skip_deploy ‚îÄ‚îÄ‚îò
```

**Explication du flux :**

1. **check_retrain_needed** : Point de d√©cision
   - Si conditions OK ‚Üí prepare_dataset
   - Sinon ‚Üí skip_retrain ‚Üí cleanup ‚Üí email "rien √† faire"

2. **prepare_dataset** : T√©l√©charge images + cr√©e labels YOLO

3. **train_model** : Fine-tuning YOLOv8

4. **validate_and_compare** : Nouveau point de d√©cision
   - Si am√©lioration ‚â• 2% ‚Üí deploy_model
   - Sinon ‚Üí skip_deploy

5. **cleanup** : Nettoie fichiers temporaires (toujours ex√©cut√©)

6. **send_report** : Email avec r√©sultats (toujours ex√©cut√©)

**trigger_rule='all_done'**
- Par d√©faut, Airflow ex√©cute une t√¢che seulement si les parents ont r√©ussi
- `all_done` : Ex√©cute m√™me si parents ont √©chou√©
- Important pour cleanup et send_report (doivent toujours s'ex√©cuter)

---

# Scripts Utilitaires

## create_monitoring_tables.py

**Objectif :** Cr√©er les tables n√©cessaires au monitoring (√† ex√©cuter une seule fois).

```python
def create_monitoring_tables():
    """Cr√©e les tables n√©cessaires pour le monitoring du mod√®le"""

    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()

    # Table pour logger chaque pr√©diction individuelle
    cur.execute("""
        CREATE TABLE IF NOT EXISTS model_predictions (
            id SERIAL PRIMARY KEY,
            image_id INTEGER REFERENCES images(id),
            batch_id VARCHAR(50),
            camera_name VARCHAR(100),
            prediction_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            fire_detected BOOLEAN,
            confidence FLOAT,
            bbox JSONB,
            model_version VARCHAR(50) DEFAULT 'yolov8s-v1',
            inference_time_ms FLOAT,
            image_size_bytes INTEGER,
            s3_path TEXT
        );
    """)

    # Autres tables (daily_metrics, model_alerts)...

    conn.commit()
    cur.close()
    conn.close()
```

**Explication :**
- `CREATE TABLE IF NOT EXISTS` : Ne cr√©e que si n'existe pas
- `SERIAL PRIMARY KEY` : ID auto-incr√©ment√©
- `REFERENCES images(id)` : Cl√© √©trang√®re vers la table images
- `JSONB` : Format JSON binaire (plus rapide que JSON)

## create_retraining_tables.py

**Objectif :** Cr√©er les tables pour le r√©entra√Ænement.

```python
def create_retraining_tables():
    """Cr√©e les tables n√©cessaires pour le r√©entra√Ænement"""

    # Table annotations
    cur.execute("""
        CREATE TABLE IF NOT EXISTS annotations (
            id SERIAL PRIMARY KEY,
            image_id INTEGER REFERENCES images(id),
            prediction_id INTEGER REFERENCES model_predictions(id),
            annotated_by VARCHAR(100) DEFAULT 'system',
            annotation_type VARCHAR(50) NOT NULL,
            is_correct BOOLEAN,
            corrected_label VARCHAR(50),
            corrected_bbox JSONB,
            confidence_score FLOAT,
            notes TEXT,
            annotated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            used_for_training BOOLEAN DEFAULT FALSE
        );
    """)

    # Table model_versions
    cur.execute("""
        CREATE TABLE IF NOT EXISTS model_versions (
            id SERIAL PRIMARY KEY,
            version_name VARCHAR(100) UNIQUE NOT NULL,
            mlflow_run_id VARCHAR(100),
            precision FLOAT,
            recall FLOAT,
            map50 FLOAT,
            deployed BOOLEAN DEFAULT FALSE,
            deployed_at TIMESTAMP,
            ...
        );
    """)
```

---

# Configuration

## .env

**CRITIQUE - Ne JAMAIS commit ce fichier !**

```bash
# AWS S3
AWS_ACCESS_KEY_ID=VOTRE_ACCESS_KEY_ICI
AWS_SECRET_ACCESS_KEY=VOTRE_SECRET_KEY_ICI
S3_BUCKET_NAME=votre-bucket-name

# PostgreSQL (Neon)
DATABASE_URL=postgresql://user:password@host/database?sslmode=require

# Email (Gmail SMTP)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=axel.vilamot@gmail.com
SMTP_PASSWORD=qsxvcjcgxgndgfse

# MLflow
MLFLOW_TRACKING_URI=http://mlflow:5000
```

**Explication :**
- Variables d'environnement charg√©es par `python-dotenv`
- Accessible via `os.getenv('AWS_ACCESS_KEY_ID')`
- **IMPORTANT** : Ce fichier contient des secrets ‚Üí `.gitignore`

## docker-compose.yml

```yaml
version: '3.8'

services:
  airflow_standalone:
    image: apache/airflow:2.8.0
    container_name: airflow_standalone
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - DATABASE_URL=${DATABASE_URL}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./scraper:/opt/airflow/scraper
      - ./model:/opt/airflow/model
      - ./monitoring:/opt/airflow/monitoring
      - ./retraining:/opt/airflow/retraining
    ports:
      - "8080:8080"
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --password admin123 --firstname Admin --lastname User --role Admin --email admin@example.com &&
        airflow standalone
      "

  mlflow_server:
    image: python:3.10
    container_name: mlflow_server
    environment:
      - MLFLOW_BACKEND_STORE_URI=${DATABASE_URL}
    ports:
      - "5001:5000"
    command: >
      bash -c "
        pip install mlflow psycopg2-binary &&
        mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri ${DATABASE_URL}
      "
```

**Explication :**

**Service airflow_standalone**
- `image: apache/airflow:2.8.0` : Version stable d'Airflow
- `volumes` : Monte les dossiers locaux dans le container
  - `./dags` ‚Üí `/opt/airflow/dags` (DAGs visibles par Airflow)
- `ports: "8080:8080"` : Expose Airflow sur http://localhost:8080
- `command` : Commandes ex√©cut√©es au d√©marrage
  - `airflow db init` : Initialise la base
  - `airflow users create` : Cr√©e l'utilisateur admin
  - `airflow standalone` : Lance Airflow en mode standalone

**Service mlflow_server**
- `image: python:3.10` : Image Python de base
- `MLFLOW_BACKEND_STORE_URI` : Stocke les runs dans Neon
- `ports: "5001:5000"` : Expose MLflow sur http://localhost:5001
- `command` : Installe MLflow et le lance

---

# Annexes

## M√©triques YOLOv8

### Precision
**D√©finition :** Sur toutes les d√©tections "feu", combien sont vraies?

**Formule :**
```
Precision = TP / (TP + FP)
```

**Exemple :**
- Le mod√®le d√©tecte 100 feux
- 85 sont de vrais feux (True Positives)
- 15 sont des faux positifs (False Positives)
- **Precision = 85 / (85 + 15) = 0.85 (85%)**

**Interpr√©tation :**
- Precision = 100% : Jamais de faux positifs (mais peut manquer des feux)
- Precision = 50% : La moiti√© des d√©tections sont des faux positifs

### Recall (Rappel)
**D√©finition :** Sur tous les vrais feux, combien sont d√©tect√©s?

**Formule :**
```
Recall = TP / (TP + FN)
```

**Exemple :**
- Il y a 100 vrais feux dans le dataset
- Le mod√®le en d√©tecte 75 (True Positives)
- 25 ne sont pas d√©tect√©s (False Negatives)
- **Recall = 75 / (75 + 25) = 0.75 (75%)**

**Interpr√©tation :**
- Recall = 100% : Tous les feux sont d√©tect√©s (mais beaucoup de faux positifs possibles)
- Recall = 50% : La moiti√© des feux ne sont pas d√©tect√©s

### mAP50 (mean Average Precision at IoU=0.5)
**D√©finition :** Pr√©cision moyenne en consid√©rant qu'une d√©tection est correcte si l'IoU ‚â• 0.5

**IoU (Intersection over Union) :**
```
IoU = Aire(Intersection) / Aire(Union)
```

**Exemple :**
- Bounding box pr√©dite : [x=0.5, y=0.5, w=0.2, h=0.3]
- Bounding box vraie : [x=0.55, y=0.52, w=0.18, h=0.28]
- Si les bo√Ætes se chevauchent √† 60% ‚Üí IoU = 0.6 ‚Üí **D√©tection correcte** (‚â• 0.5)

**Interpr√©tation :**
- mAP50 = 0.77 : Le mod√®le a 77% de pr√©cision moyenne
- C'est la m√©trique la plus importante pour YOLO

### F1-Score
**D√©finition :** Moyenne harmonique de Precision et Recall

**Formule :**
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

**Exemple :**
- Precision = 0.85
- Recall = 0.75
- **F1 = 2 * (0.85 * 0.75) / (0.85 + 0.75) = 0.797**

**Interpr√©tation :**
- F1 = 1.0 : Perfection (Precision = Recall = 100%)
- F1 √©quilibre Precision et Recall

---

## Formats de Donn√©es

### Format YOLO (labels)
```
0 0.5 0.5 0.2 0.3
‚îÇ  ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ Hauteur normalis√©e (0-1)
‚îÇ  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Largeur normalis√©e (0-1)
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Y centre (0-1)
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ X centre (0-1)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Classe (0=fire)
```

**Normalisation :**
- `x = x_pixel / largeur_image`
- `y = y_pixel / hauteur_image`
- `w = largeur_bbox / largeur_image`
- `h = hauteur_bbox / hauteur_image`

### Format JSONB (PostgreSQL)
```json
{
  "x": 0.5,
  "y": 0.5,
  "w": 0.2,
  "h": 0.3
}
```

**Avantages :**
- Requ√™table en SQL
- Flexible (peut ajouter des champs)
- Indexable

---

## Commandes Utiles

### Docker
```bash
# Lancer le syst√®me
docker-compose up -d

# Arr√™ter
docker-compose down

# Voir les logs
docker logs airflow_standalone
docker logs mlflow_server

# Red√©marrer un service
docker-compose restart airflow_standalone

# Entrer dans un container
docker exec -it airflow_standalone bash
```

### Airflow (dans le container)
```bash
# Lister les DAGs
airflow dags list

# Tester un DAG manuellement
airflow dags test fire_detection_pipeline 2026-01-09

# Voir les logs d'une t√¢che
airflow tasks logs fire_detection_pipeline scrape_cameras 2026-01-09

# Cr√©er un utilisateur
airflow users create --username admin --password admin123 --role Admin
```

### PostgreSQL (Neon)
```bash
# Se connecter (depuis Python)
import psycopg2
conn = psycopg2.connect(os.getenv('DATABASE_URL'))
cur = conn.cursor()

# Requ√™te exemple
cur.execute("SELECT COUNT(*) FROM images")
print(cur.fetchone()[0])
```

### AWS S3
```bash
# Lister les images
aws s3 ls s3://fire-detection-bucket-axelvlmt/fire_detection/ --recursive

# T√©l√©charger une image
aws s3 cp s3://fire-detection-bucket-axelvlmt/fire_detection/batch_xxx/img.png ./

# Compter les images
aws s3 ls s3://fire-detection-bucket-axelvlmt/fire_detection/ --recursive | wc -l
```

---

## Glossaire

**Airflow** : Outil d'orchestration de workflows
**DAG** : Directed Acyclic Graph (graphe de t√¢ches)
**MLflow** : Plateforme de tracking d'exp√©riences ML
**YOLOv8** : Mod√®le de d√©tection d'objets en temps r√©el
**Fine-tuning** : R√©entra√Ænement d'un mod√®le pr√©-entra√Æn√©
**Inference** : Faire une pr√©diction avec un mod√®le
**IoU** : Intersection over Union (m√©trique de chevauchement)
**mAP** : mean Average Precision (m√©trique de performance)
**Precision** : Proportion de vraies d√©tections parmi toutes les d√©tections
**Recall** : Proportion de d√©tections parmi tous les vrais positifs
**Neon** : Service PostgreSQL cloud
**S3** : Service de stockage objet AWS
**Selenium** : Outil d'automatisation de navigateur
**Batch** : Cycle de scraping (toutes les 15 minutes)

---

**FIN DE LA DOCUMENTATION**

**Pour convertir en PDF :**
1. Ouvrir ce fichier avec Visual Studio Code
2. Installer l'extension "Markdown PDF"
3. Clic droit ‚Üí "Markdown PDF: Export (pdf)"

**Ou utiliser Pandoc :**
```bash
pandoc DOCUMENTATION_CODE_DETAILLEE.md -o DOCUMENTATION_CODE_DETAILLEE.pdf --pdf-engine=xelatex
```

---

**Projet d√©velopp√© avec Claude Code**
**Contact :** axel.vilamot@gmail.com
**Date :** 2026-01-09
